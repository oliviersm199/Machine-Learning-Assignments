{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "import csv\n",
    "import functools \n",
    "import nltk\n",
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_df_train = pd.read_csv('./hwk3_datasets/IMDB-train.txt', delimiter=\"\\t\", header=None)\n",
    "imdb_df_test = pd.read_csv('./hwk3_datasets/IMDB-test.txt',   delimiter=\"\\t\",   header=None)\n",
    "imdb_df_valid = pd.read_csv('./hwk3_datasets/IMDB-valid.txt', delimiter=\"\\t\", header=None)\n",
    "\n",
    "yelp_df_train = pd.read_csv('./hwk3_datasets/yelp-train.txt', delimiter=\"\\t\", header=None)\n",
    "yelp_df_test = pd.read_csv('./hwk3_datasets/yelp-test.txt',   delimiter=\"\\t\",  header=None)\n",
    "yelp_df_valid = pd.read_csv('./hwk3_datasets/yelp-valid.txt', delimiter=\"\\t\",header=None)\n",
    "\n",
    "imdb_df_train.columns = ['review','rating']\n",
    "imdb_df_test.columns = ['review','rating']\n",
    "imdb_df_valid.columns = ['review','rating']\n",
    "yelp_df_train.columns = ['review','rating']\n",
    "yelp_df_test.columns = ['review','rating']\n",
    "yelp_df_valid.columns = ['review','rating']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def preprocessor(review):\n",
    "    '''\n",
    "    Tokenizer using a regular expression to remove punctuation.\n",
    "    Also lowercases all of the words in a review.\n",
    "    '''\n",
    "    return [word.lower() for word in tokenizer.tokenize(review)]\n",
    "    \n",
    "def create_vocab_text(df,file_name):\n",
    "    '''\n",
    "    Generates the <DatasetName>-vocab.txt file as\n",
    "    specified by the assignment 3 guidelines. \n",
    "    '''\n",
    "    df['tokenized_review'] = df['review'].apply(preprocessor)\n",
    "    cnt = Counter()\n",
    "    for review in df['tokenized_review']:\n",
    "        for word in review:\n",
    "            cnt[word] += 1\n",
    "    del df['tokenized_review']\n",
    "    most_common_ten_thousand = cnt.most_common(10000)\n",
    "    with open(file_name,'w') as file_writer:\n",
    "        writer = csv.writer(file_writer, delimiter=\"\\t\")\n",
    "        for i in range(10000):\n",
    "            writer.writerow([most_common_ten_thousand[i][0],i,\n",
    "                             most_common_ten_thousand[i][1]])\n",
    "\n",
    "def get_word_dict_from_file(file_path):\n",
    "    '''\n",
    "    Generates a dictionary of words from the assignment\n",
    "    which has the following key, value pair: word -> id \n",
    "    '''\n",
    "    WORD_DICT = {}\n",
    "    with open(file_path) as vocab_file:\n",
    "        entries = [line.strip().split(\"\\t\") for line in vocab_file]\n",
    "        for word, id_word, count in entries:\n",
    "            WORD_DICT[word] = id_word\n",
    "    return WORD_DICT\n",
    "\n",
    "def words_to_ids(text,word_dict=None):\n",
    "    '''\n",
    "    Converts a review into a list of ids, each\n",
    "    id representing a word from the <Dataset name>-vocab.txt\n",
    "    file.\n",
    "    '''\n",
    "    return [word_dict[word] for word in text if word in word_dict]\n",
    "\n",
    "def create_review_id_csv(WORD_DICT, df, file_path, delete_id_column=True, delete_tokenized_column=True):\n",
    "    '''\n",
    "    Generates the <Dataset Name>-<set type>.txt file which\n",
    "    contains the ids and the class of a particular review.\n",
    "    '''\n",
    "    df['tokenized_review'] = df['review'].apply(preprocessor)\n",
    "    word_lookup_func = functools.partial(words_to_ids, word_dict=WORD_DICT)\n",
    "    df['review_ids'] = df['tokenized_review'].apply(word_lookup_func)\n",
    "    if delete_tokenized_column:\n",
    "        del df['tokenized_review']\n",
    "    with open(file_path, 'w') as review_id_file:\n",
    "        writer = csv.writer(review_id_file, delimiter=\"\\t\")\n",
    "        for rating, review_ids in zip(df['rating'],df['review_ids']):\n",
    "            space_separated_ids = ' '.join(review_ids)\n",
    "            writer.writerow([space_separated_ids, rating])\n",
    "    if delete_id_column:\n",
    "        del df['review_ids']  \n",
    "\n",
    "def binary_bag_of_words_vectorizer(WORD_DICT, review):\n",
    "    '''\n",
    "    Generates the binary bag of words representation of a \n",
    "    review as specified in the assignment.\n",
    "    '''\n",
    "    review_list = set(preprocessor(review))\n",
    "    vector = np.asarray([1 if key in review_list else 0 for key in WORD_DICT])\n",
    "    return vector\n",
    "\n",
    "\n",
    "def frequency_bag_of_words_vectorizer(WORD_DICT, review):\n",
    "    '''\n",
    "    Generates the frequency bag of words representation of a \n",
    "    review, as specified in the assignment. \n",
    "    '''\n",
    "    review_list = preprocessor(review)\n",
    "    review_list_top_words = [word for word in review_list if word in WORD_DICT]\n",
    "    global_occurences = len(review_list_top_words)\n",
    "    counter = Counter(review_list_top_words)\n",
    "    freq_dict = {}\n",
    "    for word in counter.keys():\n",
    "        word_occurences = counter[word]\n",
    "        frequency = float(word_occurences) / float(global_occurences)\n",
    "        freq_dict[word] = frequency\n",
    "    vector = np.asarray([freq_dict[word] if word in freq_dict else 0 for word in WORD_DICT])\n",
    "    return vector\n",
    "\n",
    "\n",
    "def get_binary_bag_vectorized_representation(WORD_DICT, df):\n",
    "    training_list = []\n",
    "    for review, rating in zip(df['review'], df['rating']):\n",
    "        review_vector = binary_bag_of_words_vectorizer(WORD_DICT, review)\n",
    "        review_vector_with_class =np.append(review_vector, rating)\n",
    "        training_list.append(review_vector_with_class)\n",
    "        \n",
    "    return np.asarray(training_list)\n",
    "\n",
    "def get_frequency_bag_vectorized_representation(WORD_DICT, df):\n",
    "    training_list = []\n",
    "    for review, rating in zip(df['review'], df['rating']):\n",
    "        review_vector = frequency_bag_of_words_vectorizer(WORD_DICT, review)\n",
    "        review_vector_with_class =np.append(review_vector, rating)\n",
    "        training_list.append(review_vector_with_class)\n",
    "    return np.asarray(training_list)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Training/Validating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_classifier(training_set):\n",
    "    '''\n",
    "    Will return a random choice classifier from all \n",
    "    possible labels.This assumes that the training set \n",
    "    has the class labels in the last column of a numpy \n",
    "    array. Returns a function. To classifiy, you need to\n",
    "    pass a review vector.\n",
    "    '''\n",
    "    classes = list(set(training_set[:,-1]))\n",
    "    return lambda review: random.choice(classes)\n",
    "\n",
    "def get_majority_classifier(training_set):\n",
    "    '''\n",
    "    Will always return the majority. This assumes that the\n",
    "    training set has the class labels in the last column\n",
    "    of a numpy array. Returns a function. To classifiy, \n",
    "    you need to pass a review vector.\n",
    "    '''\n",
    "    classes = training_set[:,-1]\n",
    "    counter = Counter(classes)\n",
    "    return lambda review : counter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bern_bayes_classifier_f1_scores(alphas, training_set, validation_set):\n",
    "    '''\n",
    "    Returns the f1 averages for each alpha passed in \n",
    "    the method over the target training/validation set.\n",
    "    '''\n",
    "    alphas = alphas\n",
    "    f1_averages = []\n",
    "    for alpha in alphas:\n",
    "        model = BernoulliNB(alpha=alpha)\n",
    "        X = training_set[:,:-1]\n",
    "        Y = training_set[:,-1]\n",
    "        model.fit(X, Y)\n",
    "        XV = validation_set[:,:-1]\n",
    "        YV = validation_set[:,-1]\n",
    "        YPRED = model.predict(XV)\n",
    "        f1_average = np.average(f1_score(YV,YPRED,average=None))\n",
    "        f1_averages.append(f1_average)\n",
    "    return f1_averages\n",
    "\n",
    "def get_bern_bayes_classifier_f1_score(alpha, training_set, test_set):\n",
    "    model = BernoulliNB(alpha = alpha)   \n",
    "    X = training_set[:,:-1]\n",
    "    Y = training_set[:,-1]\n",
    "    model.fit(X, Y)\n",
    "    XT = test_set[:,:-1]\n",
    "    YT = test_set[:,-1]\n",
    "    YPRED = model.predict(XT)\n",
    "    return np.average(f1_score(YT,YPRED,average=None))\n",
    "\n",
    "def get_naive_bayes_classifier_f1_score(training_set, test_set):\n",
    "    model = GaussianNB()   \n",
    "    X = training_set[:,:-1]\n",
    "    Y = training_set[:,-1]\n",
    "    model.fit(X, Y)\n",
    "    XT = test_set[:,:-1]\n",
    "    YT = test_set[:,-1]\n",
    "    YPRED = model.predict(XT)\n",
    "    return np.average(f1_score(YT,YPRED,average=None))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_decision_tree_classifier(param_grid, training_set, validation_set):\n",
    "    dt_model = DecisionTreeClassifier()\n",
    "    \n",
    "    # Made an f1 average scorer out of f1_score\n",
    "    scorer = make_scorer(f1_average_score)\n",
    "    train_valid_set = np.concatenate([training_set,validation_set])\n",
    "    test_fold = np.concatenate([np.zeros((len(training_set),)), np.full((len(validation_set),),fill_value=-1)])\n",
    "    X = train_valid_set[:,:-1]\n",
    "    Y = train_valid_set[:,-1]\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    clf = GridSearchCV(estimator=dt_model, # use the decision tree model\n",
    "                   scoring=scorer, # use f1 score to determine the best\n",
    "                   n_jobs=-1, # parallelize as much as OS allows\n",
    "                   cv=ps, # use the predefined training/test split to determine the optimal params \n",
    "                   param_grid=param_grid, # test over the following grid\n",
    "                  )\n",
    "    clf.fit(X,Y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_classifier(param_grid, training_set, validation_set):\n",
    "    svm_model = LinearSVC()\n",
    "    \n",
    "    # Made an f1 average scorer out of f1_score\n",
    "    scorer = make_scorer(f1_average_score)\n",
    "    \n",
    "    train_valid_set = np.concatenate([training_set,validation_set])\n",
    "    test_fold = np.concatenate([np.zeros((len(training_set),)), np.full((len(validation_set),),fill_value=-1)])\n",
    "    X = train_valid_set[:,:-1]\n",
    "    Y = train_valid_set[:,-1]\n",
    "    ps = PredefinedSplit(test_fold)\n",
    "    clf = GridSearchCV(\n",
    "                   estimator=svm_model, # use the decision tree model\n",
    "                   scoring=scorer, # use f1 score to determine the best\n",
    "                   cv=ps, # use the predefined training/test split to determine the optimal params \n",
    "                   param_grid=param_grid, # test over the following grid\n",
    "                  )\n",
    "    clf.fit(X,Y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predictions(classifier, testing_set):\n",
    "    '''\n",
    "    This function will iterate through a testing set\n",
    "    and gather the predictions for that test set. This assumes\n",
    "    that the last row in the test set is the class labels, which\n",
    "    are removed and not provided as input to the classifier.\n",
    "    '''\n",
    "    predictions = [] \n",
    "    for sample in testing_set:\n",
    "        features = sample[:-1]\n",
    "        prediction = classifier(features)\n",
    "        predictions.append(prediction)\n",
    "    return np.array(predictions)\n",
    "\n",
    "def f1_average_score(y, ypred, **kwargs):\n",
    "    return np.average(f1_score(y,ypred,average=None,**kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating text files for dataset submission \n",
    "create_vocab_text(imdb_df_train, 'IMDB-vocab.txt')\n",
    "create_vocab_text(yelp_df_train, 'YELP-vocab.txt')\n",
    "\n",
    "IMDB_WORD_DICT = get_word_dict_from_file('IMDB-vocab.txt')\n",
    "YELP_WORD_DICT = get_word_dict_from_file('YELP-vocab.txt')\n",
    "\n",
    "create_review_id_csv(IMDB_WORD_DICT, imdb_df_train, 'IMDB-train.txt')\n",
    "create_review_id_csv(IMDB_WORD_DICT, imdb_df_valid, 'IMDB-valid.txt')\n",
    "create_review_id_csv(IMDB_WORD_DICT, imdb_df_test, 'IMDB-test.txt')\n",
    "create_review_id_csv(YELP_WORD_DICT, yelp_df_train, 'YELP-train.txt')\n",
    "create_review_id_csv(YELP_WORD_DICT, yelp_df_valid, 'YELP-valid.txt')\n",
    "create_review_id_csv(YELP_WORD_DICT, yelp_df_test, 'YELP-test.txt')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Yelp datasets into binary bag representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YELP_WORD_DICT = get_word_dict_from_file('YELP-vocab.txt')\n",
    "yelp_training_set = get_binary_bag_vectorized_representation(YELP_WORD_DICT, yelp_df_train)\n",
    "yelp_valid_set = get_binary_bag_vectorized_representation(YELP_WORD_DICT, yelp_df_valid)\n",
    "yelp_test_set = get_binary_bag_vectorized_representation(YELP_WORD_DICT, yelp_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Classifier F1 Score\n",
      "\n",
      "0.188141655581\n",
      "\n",
      "Majority Classifier F1 Score\n",
      "\n",
      "0.103923019985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Initializing classifiers for baseline estimates \n",
    "majority_classifier = get_majority_classifier(yelp_training_set)\n",
    "random_classifier = get_random_classifier(yelp_training_set)\n",
    "\n",
    "# Test classes vector \n",
    "test_classes = yelp_test_set[:,-1]\n",
    "\n",
    "# Get the predictions from each baseline classifier \n",
    "random_classifier_predictions_test = get_predictions(random_classifier, yelp_test_set)\n",
    "majority_classifier_predictions_test = get_predictions(majority_classifier, yelp_test_set)\n",
    "\n",
    "# Print F1 Score for each classifier\n",
    "print(\"\\nRandom Classifier F1 Score\\n\")\n",
    "print(f1_average_score(test_classes, random_classifier_predictions_test))\n",
    "print(\"\\nMajority Classifier F1 Score\\n\")\n",
    "print(f1_average_score(test_classes, majority_classifier_predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning over various alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a30ce50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum alpha was 0.18859 and the F1 average was 0.36243\n",
      "\n",
      "Alphas Tested:\n",
      "\n",
      "[  1.00000000e-10   1.60739439e-10   2.58371673e-10   4.15305179e-10\n",
      "   6.67559216e-10   1.07303094e-09   1.72478392e-09   2.77240800e-09\n",
      "   4.45635307e-09   7.16311693e-09   1.15139540e-08   1.85074651e-08\n",
      "   2.97487956e-08   4.78180472e-08   7.68624610e-08   1.23548289e-07\n",
      "   1.98590827e-07   3.19213781e-07   5.13102442e-07   8.24757988e-07\n",
      "   1.32571137e-06   2.13094102e-06   3.42526264e-06   5.50574796e-06\n",
      "   8.84990840e-06   1.42252931e-05   2.28656564e-05   3.67541279e-05\n",
      "   5.90783791e-05   9.49622553e-05   1.52641797e-04   2.45355568e-04\n",
      "   3.94383164e-04   6.33929287e-04   1.01897438e-03   1.63789371e-03\n",
      "   2.63274116e-03   4.23185338e-03   6.80225739e-03   1.09339104e-02\n",
      "   1.75751062e-02   2.82501272e-02   4.54090961e-02   7.29903265e-02\n",
      "   1.17324241e-01   1.88586328e-01   3.03132606e-01   4.87253651e-01\n",
      "   7.83208787e-01   1.25892541e+00]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-10,0.1)\n",
    "f1_scores = get_bern_bayes_classifier_f1_scores(alphas, yelp_training_set, yelp_valid_set)\n",
    "\n",
    "pyplot.scatter(alphas,f1_scores)\n",
    "pyplot.title(\"Alpha vs. F1 Score on Yelp Validation Datset\")\n",
    "pyplot.xlabel(\"Additive smoothing parameter\")\n",
    "pyplot.ylabel(\"Average F1 Score over different classes\")\n",
    "pyplot.show()\n",
    "\n",
    "max_alpha = max(zip(alphas,f1_scores),key=lambda x : x[1])\n",
    "print(\"The maximum alpha was %.5f and the F1 average was %.5f\"%max_alpha)\n",
    "print(\"\\nAlphas Tested:\\n\")\n",
    "print(alphas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Average on the Test Set is 0.38626\n"
     ]
    }
   ],
   "source": [
    "f1_average = get_bern_bayes_classifier_f1_score(max_alpha[0],yelp_training_set, yelp_test_set)\n",
    "print(\"The F1 Average on the Test Set is %.5f\"%(f1_average))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Scikit Learn library has a section here covering the usage of the DecisionTreeClassifier class. To summarize the following parameters are recommended for tuning:\n",
    "\n",
    "* max_depth\n",
    "* min_samples_split\n",
    "* min_samples_leaf\n",
    "\n",
    "These were the hyper parameters used for training. Since there is more than one parameter, a matrix of parameter choices will have to be covered and GridSearchCV will help to do this. GridSearchCV takes the estimator and the parameters and trains a model on each parameter. Then it will return a matrix of the optimal parameter combinations and you can also ask for the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'max_features':[\"auto\",\"sqrt\",\"log2\"]\n",
    "             }\n",
    "\n",
    "clf = get_decision_tree_classifier(param_grid,yelp_training_set, yelp_valid_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 score was 0.25140 and came with the parameters: {'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "                \"C\": np.linspace(0.001,0.1,5),\n",
    "                \"tol\": np.logspace(-15,-8,3)\n",
    "             }\n",
    "svm_model = LinearSVC()\n",
    "clf = get_svm_classifier(param_grid, yelp_training_set, yelp_valid_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 score was 0.38885 and came with the parameters: {'C': 0.025750000000000002, 'tol': 1.0000000000000001e-15}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Yelp datasets using frequency bag of words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "YELP_WORD_DICT = get_word_dict_from_file('YELP-vocab.txt')\n",
    "yelp_training_set_freq = get_frequency_bag_vectorized_representation(YELP_WORD_DICT, yelp_df_train)\n",
    "yelp_valid_set_freq = get_frequency_bag_vectorized_representation(YELP_WORD_DICT, yelp_df_valid)\n",
    "yelp_test_set_freq = get_frequency_bag_vectorized_representation(YELP_WORD_DICT, yelp_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score was 0.25787 and the test score was 0.25265\n"
     ]
    }
   ],
   "source": [
    "f1_score_validation = get_naive_bayes_classifier_f1_score(yelp_training_set_freq, yelp_valid_set_freq)\n",
    "f1_score_test = get_naive_bayes_classifier_f1_score(yelp_training_set_freq, yelp_test_set_freq)\n",
    "print(\"The validation score was %.5f and the test score was %.5f\"%(f1_score_test, f1_score_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'max_features':[\"auto\",\"sqrt\",\"log2\"]\n",
    "             }\n",
    "\n",
    "clf = get_decision_tree_classifier(param_grid,yelp_training_set_freq, yelp_valid_set_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 score was 0.25323 and came with the parameters: {'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "svm_model = LinearSVC()\n",
    "clf = get_svm_classifier(param_grid, yelp_training_set_freq, yelp_valid_set_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 score was 0.18362 and came with the parameters: {}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting IMDB datasets using binary bag of words representation and frequency bag of words representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-09a1f38d232e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimdb_training_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_binary_bag_vectorized_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMDB_WORD_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_df_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimdb_valid_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_binary_bag_vectorized_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMDB_WORD_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_df_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimdb_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_binary_bag_vectorized_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMDB_WORD_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_df_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimdb_training_set_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frequency_bag_vectorized_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMDB_WORD_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_df_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimdb_valid_set_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_frequency_bag_vectorized_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMDB_WORD_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimdb_df_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-79a29639e253>\u001b[0m in \u001b[0;36mget_binary_bag_vectorized_representation\u001b[0;34m(WORD_DICT, df)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mtraining_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mreview_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_bag_of_words_vectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORD_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mreview_vector_with_class\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtraining_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_vector_with_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-79a29639e253>\u001b[0m in \u001b[0;36mbinary_bag_of_words_vectorizer\u001b[0;34m(WORD_DICT, review)\u001b[0m\n\u001b[1;32m     70\u001b[0m     '''\n\u001b[1;32m     71\u001b[0m     \u001b[0mreview_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview_list\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWORD_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IMDB_WORD_DICT = get_word_dict_from_file('IMDB-vocab.txt')\n",
    "imdb_training_set = get_binary_bag_vectorized_representation(IMDB_WORD_DICT, imdb_df_train)\n",
    "imdb_valid_set = get_binary_bag_vectorized_representation(IMDB_WORD_DICT, imdb_df_valid)\n",
    "imdb_test_set = get_binary_bag_vectorized_representation(IMDB_WORD_DICT, imdb_df_test)\n",
    "imdb_training_set_freq = get_frequency_bag_vectorized_representation(IMDB_WORD_DICT, imdb_df_train)\n",
    "imdb_valid_set_freq = get_frequency_bag_vectorized_representation(IMDB_WORD_DICT, imdb_df_valid)\n",
    "imdb_test_set_freq = get_frequency_bag_vectorized_representation(IMDB_WORD_DICT, imdb_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-10,0.1)\n",
    "f1_scores = get_bern_bayes_classifier_f1_scores(alphas, imdb_training_set, imdb_valid_set)\n",
    "\n",
    "pyplot.scatter(alphas,f1_scores)\n",
    "pyplot.title(\"Alpha vs. F1 Score on IMDB Validation Datset\")\n",
    "pyplot.xlabel(\"Additive smoothing parameter\")\n",
    "pyplot.ylabel(\"Average F1 Score over different classes\")\n",
    "pyplot.show()\n",
    "\n",
    "max_alpha = max(zip(alphas,f1_scores),key=lambda x : x[1])\n",
    "print(\"The maximum alpha was %.5f and the F1 average was %.5f\"%max_alpha)\n",
    "print(\"\\nAlphas Tested:\\n\")\n",
    "print(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'max_features':[\"auto\",\"sqrt\",\"log2\"]\n",
    "             }\n",
    "\n",
    "clf = get_decision_tree_classifier(param_grid,imdb_training_set, imdb_valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "                \"C\": np.linspace(0.001,0.1,5),\n",
    "                \"tol\": np.logspace(-15,-8,3)\n",
    "             }\n",
    "svm_model = LinearSVC()\n",
    "clf = get_svm_classifier(param_grid, imdb_training_set, imdb_valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score_validation = get_naive_bayes_classifier_f1_score(imdb_training_set_freq, imdb_valid_set_freq)\n",
    "f1_score_test = get_naive_bayes_classifier_f1_score(imdb_training_set_freq, imdb_test_set_freq)\n",
    "print(\"The validation score was %.5f and the test score was %.5f\"%(f1_score_test, f1_score_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "              'max_features':[\"auto\",\"sqrt\",\"log2\"]\n",
    "             }\n",
    "\n",
    "clf = get_decision_tree_classifier(param_grid, imdb_training_set_freq, imdb_valid_set_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "                \"C\": np.linspace(0.001,0.1,5),\n",
    "                \"tol\": np.logspace(-15,-8,3)\n",
    "             }\n",
    "svm_model = LinearSVC()\n",
    "clf = get_svm_classifier(param_grid, imdb_training_set_freq, imdb_valid_set_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"The best F1 score was %.5f and came with the parameters: %s\"%(clf.best_score_,clf.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
